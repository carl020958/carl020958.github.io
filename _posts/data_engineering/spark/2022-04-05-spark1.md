---
title: "[Spark] SPARK 개념 정리"
layout: single
date: '5/4/2022'
toc: true
toc_sticky: true
toc_label: Table of Contents
categories:
  - SPARK
tags:
  - SPARK
---

---
### SPARK 개념 정리
* Glossary
* Spark Cluster Mode Overview
* Spark-Submit 실행순서
* YARN에서의 실행
  * YARN Cluster Mode
  * YARN Client Mode
* Deployment Mode Summary

---

#### Glossary
<table class="table">
  <thead>
    <tr><th style="width: 130px;">Term</th><th>Meaning</th></tr>
  </thead>
  <tbody>
    <tr>
      <td>Application</td>
      <td>User program built on Spark. Consists of a <em>driver program</em> and <em>executors</em> on the cluster.</td>
    </tr>
    <tr>
      <td>Application jar</td>
      <td>
        A jar containing the user's Spark application. In some cases users will want to create
        an "uber jar" containing their application along with its dependencies. The user's jar
        should never include Hadoop or Spark libraries, however, these will be added at runtime.
      </td>
    </tr>
    <tr>
      <td>Driver program</td>
      <td>The process running the main() function of the application and creating the SparkContext</td>
    </tr>
    <tr>
      <td>Cluster manager</td>
      <td>An external service for acquiring resources on the cluster (e.g. standalone manager, Mesos, YARN, Kubernetes)</td>
    </tr>
    <tr>
      <td>Deploy mode</td>
      <td>Distinguishes where the driver process runs. In "cluster" mode, the framework launches
        the driver inside of the cluster. In "client" mode, the submitter launches the driver
        outside of the cluster.</td>
    </tr>
    <tr>
      <td>Worker node</td>
      <td>Any node that can run application code in the cluster</td>
    </tr>
    <tr>
      <td>Executor</td>
      <td>A process launched for an application on a worker node, that runs tasks and keeps data in memory
        or disk storage across them. Each application has its own executors.</td>
    </tr>
    <tr>
      <td>Task</td>
      <td>A unit of work that will be sent to one executor</td>
    </tr>
    <tr>
      <td>Job</td>
      <td>A parallel computation consisting of multiple tasks that gets spawned in response to a Spark action
        (e.g. <code>save</code>, <code>collect</code>); you'll see this term used in the driver's logs.</td>
    </tr>
    <tr>
      <td>Stage</td>
      <td>Each job gets divided into smaller sets of tasks called <em>stages</em> that depend on each other
        (similar to the map and reduce stages in MapReduce); you'll see this term used in the driver's logs.</td>
    </tr>
  </tbody>
</table>
---

#### Spark Cluster Mode Overview
* Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program)
* Specifically, to run on a cluster, the SparkContext can connect to several types of cluster managers(Standalone, Mesos, YARN or Kubernetes), which allocate resources across applications
* Once connected, Spark acquires executors on nodes in the cluster, which are processes that run computations and store data for your application
* Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors
* Finally, SparkContext sends tasks to the executors to run

<p align="center">
    <img src="/img/data_engineering/spark/spark_cluster.png" align="center">
</p>

---

#### Spark-Submit 실행순서
* 1) $SPARK_HOME/bin/spark-submit을 이용하여 Application 제출
* 2) Driver Program이 실행되며(main()함수 실행) & SparkContext가 생성(즉, Spark Cluster와의 연결이 이루어짐)
* 3) Driver가 Cluster Manager(Standalone, Mesos, YARN, Kubernetes)에게 Executor 리소스 요청
* 4) Cluster Manager가 Worker (Node)에게 Executor 띄우도록 명령
* 5) Driver Program이 DAG Scheduling을 통해 작업을 Task 단위로 분할하여 Executor에게 할당
* 6) Executor가 여러 스레드에서 Task들을 실행한 후 결과를 Driver Program에게 보냄
* 7) Application이 완료되면서 리소스를 Cluster Manager에게 반환

---

#### YARN에서의 실행
* When Spark applications run on a YARN cluster manager, resource management, scheduling, and security are controlled by YARN.
* In YARN, each application instance has an ApplicationMaster process, which is the first container started for that application.
* The application is responsible for requesting resources from the ResourceManager. 
* Once the resources are allocated, the application instructs NodeManagers to start containers on its behalf. 
* ApplicationMasters eliminate the need for an active client: the process starting the application can terminate, and coordination continues from a process managed by YARN running on the cluster.

##### YARN Cluster Mode
* Spark driver runs in the ApplicationMaster on a cluster host.
* A single process in a YARN container is responsible for both driving the application and requesting resources from YARN. 
* The client that launches the application does not need to run for the lifetime of the application.

<p align="center">
    <img src="/img/data_engineering/spark/spark_yarn_cluster.png" align="center">
</p>

##### YARN Client Mode
* Spark driver runs on the host where the job is submitted
* The ApplicationMaster is responsible only for requesting executor containers from YARN
* After the containers start, the client communicates with the containers to schedule work

<p align="center">
    <img src="/img/data_engineering/spark/spark_yarn_client.png" align="center">
</p>

---

### Deployment Mode Summary

<table id="deployment_modes__table_qqq_pbf_2s" class="table">
<caption xmlns="http://www.w3.org/1999/xhtml"><span class="tablecap"><span class="tablecap">Deployment Mode Summary</span></span></caption>
<thead class="thead" align="left">
<tr class="row">
<th class="entry" valign="top" id="d4066467e111">Mode</th>
<th class="entry" valign="top" id="d4066467e117">YARN Cluster Mode</th>
<th class="entry" valign="top" id="d4066467e114">YARN Client Mode</th>
<th class="entry" valign="top" id="d4066467e117">Spark Standalone</th>
</tr>
</thead>
<tbody class="tbody">
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Driver runs in</strong></td>
<td class="entry" valign="top" headers="d4066467e117">ApplicationMaster</td>
<td class="entry" valign="top" headers="d4066467e114">Client</td>
<td class="entry" valign="top" headers="d4066467e114">Client</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Requests resources</strong></td>
<td class="entry" valign="top" headers="d4066467e117">ApplicationMaster</td>
<td class="entry" valign="top" headers="d4066467e114">ApplicationMaster</td>
<td class="entry" valign="top" headers="d4066467e114">Client</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Starts executor processes</strong></td>
<td class="entry" valign="top" headers="d4066467e117">YARN NodeManager</td>
<td class="entry" valign="top" headers="d4066467e114">YARN NodeManager</td>
<td class="entry" valign="top" headers="d4066467e114">Spark Workers(Slaves)</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Persistent services</strong></td>
<td class="entry" valign="top" headers="d4066467e114">YARN ResourceManager and NodeManagers</td>
<td class="entry" valign="top" headers="d4066467e117">YARN ResourceManager and NodeManagers</td>
<td class="entry" valign="top" headers="d4066467e117">Spark Masters & Workers</td>
</tr>
<tr class="row">
<td class="entry" valign="top" headers="d4066467e111"><strong class="ph b">Supports Spark Shell</strong></td>
<td class="entry" valign="top" headers="d4066467e117">No</td>
<td class="entry" valign="top" headers="d4066467e114">Yes</td>
<td class="entry" valign="top" headers="d4066467e114">Yes</td>
</tr>
</tbody>
</table>

---

### ref
* [🔗 SPARK 공식문서](https://spark.apache.org/docs/latest/cluster-overview.html)
* [🔗 SPARK Configuration](https://spark.apache.org/docs/latest/configuration.html)
* [🔗 Cloudera 블로그](https://docs.cloudera.com/documentation/enterprise/latest/topics/cdh_ig_running_spark_on_yarn.html)
* [🔗 참고 블로그](https://12bme.tistory.com/437)
* [🔗 참고 블로그2](http://incredible.ai/spark/2016/02/11/Spark-YARN-Cluster/)
* [🔗 참고 블로그3](https://paranwater.tistory.com/417)
* [🔗 참고 블로그4](https://wooono.tistory.com/58)
