---
title: "[Spark] Spark Executor 설정"
layout: single
date: '9/4/2022'
toc: true
toc_sticky: true
toc_label: Table of Contents
categories:
  - SPARK
tags:
  - SPARK
---

---
### Spark Executor 설정
* 간단 요약
* Spark Executor 기본 전제
* 작은 Executor와 큰 Executor의 문제

---

### 간단 요약
* 서버(모든 노드)의 전체 Core, Memory 값 구하기
* --executor-cores은 0~5 사이값으로 정하기
* --num-executors (사용 가능한 전체 Executor 수 구하기)
  * (--num-executors ) x (--executor-cores) < 서버 전체 Core 수
* 각 노드 당 할당되는 Executor 개수 구하기
  * --num-executors / 전체 서버 개수
* --executor-memory (Executor당 할당될 memory)
  * 서버 1개의 Memory / 서버 1개의 Executor 개수

---

### Spark Executor 기본 전제
* Executor는 캐싱과 실행을 위한 공간을 갖고 있는 JVM임
* Executor와 driver의 사이즈는 하나의 노드나 컨테이너에 할당된 자원보다 많은 메모리나 코어를 가질 수 없음
* Executor의 일부 공간은 스파크의 내부 메타 데이터와 사용자 자료구조를 위해 예약되어야 함
* 하나의 Partition은 하나의 Executor에서 처리

---

### ref
* [🔗 참고블로그1](https://jaemunbro.github.io/posts/spark-config-executors/)
* [🔗 참고블로그2](https://wooono.tistory.com/120)
* [🔗 참고블로그3](https://gritmind.blog/2020/10/16/spark_tune/)
* [🔗 참고블로그4](https://m.blog.naver.com/gyrbsdl18/220880041737)

